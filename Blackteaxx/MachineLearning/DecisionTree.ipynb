{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "            [1, 1, 'yes'],\n",
    "            [1, 0, 'no'],\n",
    "            [0, 1, 'no'],\n",
    "            [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def calcShannonEnt(dataset):\n",
    "    numEntries = len(dataset)\n",
    "    labelCounts = {}\n",
    "\n",
    "    for featVec in dataset:\n",
    "        currentLabel = featVec[-1]\n",
    "\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "\n",
    "\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = labelCounts[key] / numEntries\n",
    "        shannonEnt += -1 * prob * math.log2(prob)\n",
    "\n",
    "    return shannonEnt\n",
    "\n",
    "calcShannonEnt(createDataSet()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def splitDataSet(dataset, index, value):\n",
    "    \"\"\"\n",
    "    splitDataSet(通过遍历dataSet数据集，求出index对应的colnum列的值为value的行)\n",
    "        就是依据index列进行分类，如果index列的数据等于 value的时候，就要将 index 划分到我们创建的新的数据集中\n",
    "    Args:\n",
    "        dataSet 数据集                 待划分的数据集\n",
    "        index 表示每一行的index列        划分数据集的特征\n",
    "        value 表示index列对应的value值   需要返回的特征的值。\n",
    "    Returns:\n",
    "        index列为value的数据集【该数据集需要排除index列】\n",
    "    \"\"\"\n",
    "    retDataSet = []\n",
    "    for featVec in dataset:\n",
    "        if featVec[index] == value:\n",
    "            reducedFeatVec = featVec[:index]\n",
    "            reducedFeatVec.extend(featVec[index+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "splitDataSet(createDataSet()[0],1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataset):\n",
    "    \"\"\"chooseBestFeatureToSplit(选择最好的特征)\n",
    "\n",
    "    Args:\n",
    "        dataSet 数据集\n",
    "    Returns:\n",
    "        bestFeature 最优的特征列\n",
    "    \"\"\"\n",
    "    numFeatures = len(dataset[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataset)\n",
    "\n",
    "    bestInfoGain, bestFeatureIndex = 0.0, -1\n",
    "\n",
    "    # 遍历每一个特征，计算最优的信息增益的列\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataset]\n",
    "        uniqueVals = set(featList)\n",
    "\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subdataset = splitDataSet(dataset, i, value)\n",
    "            newEntropy += len(subdataset) / len(dataset) * calcShannonEnt(subdataset)\n",
    "\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        print(\"infoGain=\", infoGain, \"baseFeature: \", i)\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeatureIndex = i\n",
    "\n",
    "    return bestFeatureIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    \"\"\"majorityCnt(选择出现次数最多的一个结果)\n",
    "    Args:\n",
    "        classList label列的集合\n",
    "    Returns:\n",
    "        bestFeature 最优的特征列\n",
    "    \"\"\"\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    if classCount['yes'] > classCount['no']:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataset, labels):\n",
    "    classList = [example[-1] for example in dataset]\n",
    "\n",
    "    # 第一个停止条件：所有类标签完全相同\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    \n",
    "    # 第二个停止条件：使用完了所有的特征，仍然不能将数据集划分成仅有唯一类别的分组\n",
    "    if len(dataset[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "\n",
    "    \n",
    "    bestFeat = chooseBestFeatureToSplit(dataset)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    # 注: labels列表是可变对象，在PYTHON函数中作为参数时传址引用，能够被全局修改\n",
    "    # 所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list\n",
    "    del(labels[bestFeat])\n",
    "\n",
    "    # 取出最优列，然后它的branch做分类\n",
    "    featValues = [example[bestFeat] for example in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        # 求出剩余的标签label\n",
    "        subLabels = labels[:]\n",
    "        # 遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree()\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataset, bestFeat, value), subLabels)\n",
    "        print('myTree', value, myTree)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infoGain= 0.4199730940219749 baseFeature:  0\n",
      "infoGain= 0.17095059445466854 baseFeature:  1\n",
      "myTree 0 {'no surfacing': {0: 'no'}}\n",
      "infoGain= 0.9182958340544896 baseFeature:  0\n",
      "myTree 0 {'flippers': {0: 'no'}}\n",
      "myTree 1 {'flippers': {0: 'no', 1: 'yes'}}\n",
      "myTree 1 {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset, labels = createDataSet()\n",
    "    myTree = createTree(dataset, labels)\n",
    "    print(myTree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
