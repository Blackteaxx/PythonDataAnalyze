Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3,mfinal=100,boos=T)
p$confusion
p <- predict(ada.model, newdata=train)
p <- predict(ada.model, newdata=train)
p$confusion
p$error
library(randomForest)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=20, mtry = 10)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
plotTestROC <- function(model, theme) {
pre_ran <- predict(model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTrainROC <- function(model, theme) {
pre_ran <- predict(model, newdata=train)
ran_roc <- roc(train$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTestROC <- function(model, theme) {
pre_ran <- predict(model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTrainROC <- function(model, theme) {
pre_ran <- predict(model, newdata=train)
ran_roc <- roc(train$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
library(caret)
if(file.exists('rda/rf_manual.rda')){
results <- readRDS("rda/rf_manual.rda")
} else {
# Manual Search
trControl <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
# 用默认值固定mtry
tunegrid <- expand.grid(mtry=c(5,10,15,20,25,30))
# 定义模型列表，存储每一个模型评估结果
modellist <- list()
# 调整的参数是决策树的数量
for (ntree in c(100,150,200,250,300,350,400,450,500,550)) {
fit <- train(x=train.df, y=metadata[[group]], method="rf",
metric="Accuracy", tuneGrid=tunegrid,
trControl=trControl, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
saveRDS(results, "rda/rf_manual.rda")
}
# Manual Search
trControl <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
# 用默认值固定mtry
tunegrid <- expand.grid(mtry=c(5,10,15,20,25,30))
# 用默认值固定mtry
tunegrid <- expand.grid(mtry=c(5,10,15,20))
# 定义模型列表，存储每一个模型评估结果
modellist <- list()
# 调整的参数是决策树的数量
for (ntree in c(100,150,200,250,300,350,400,450,500,550)) {
fit <- train(x=train.df, y=metadata[[group]], method="rf",
metric="Accuracy", tuneGrid=tunegrid,
trControl=trControl, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
View(over_sampled3)
train.df <- select(both_sampled3, -c("var1_new", "var2_new", "var3_new", "result", "shares")
# 调整的参数是决策树的数量
for (ntree in c(100,150,200,250,300,350,400,450,500)) {
# 调整的参数是决策树的数量
for (ntree in c(100,150,200,250,300,350,400,450,500)) {
fit <- train(x=select(train.df, -c("result2")), y=train.df$result2, method="rf",
metric="Accuracy", tuneGrid=tunegrid,
trControl=trControl, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
help(tree)
View(modellist)
modellist[["100"]]
train.df <- select(both_sampled3, -c("var1_new", "var2_new", "var3_new", "result", "shares"))
print("训练完成", ntree)
print(paste0("训练完成", ntree))
# 定义模型列表，存储每一个模型评估结果
modellist <- list()
# 调整的参数是决策树的数量
for (ntree in c(100,150,200,250,300,350,400,450,500)) {
fit <- train(x=select(train.df, -c("result2")), y=train.df$result2, method="rf",
metric="Accuracy", tuneGrid=tunegrid,
trControl=trControl, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
print(paste0("训练完成:", ntree))
}
View(modellist)
# 定义模型列表，存储每一个模型评估结果
modellist <- list()
# 调整的参数是决策树的数量
for (ntree in c(100,150,200,250,300,350,400,450,500)) {
fit <- train(x=select(train.df, -c("result2")), y=train.df$result2, method="rf",
metric="Accuracy", tuneGrid=tunegrid,
trControl=trControl, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
print(paste0("训练完成:", ntree))
}
View(modellist)
modellist[["100"]]
modellist[["150"]]
results <- resamples(modellist)
saveRDS(results, "rda/rf_manual.rda")
summary(results)
View(modellist)
modellist
modellist[["100"]]
dotplot(results)
View(results)
n# compare results
dotplot(results)
summary(results)
View(modellist)
modellist
modellist
dotplot(results)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseGini,
decreasing = T),]
head(importance.df)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseGini,
decreasing = T),]
head(importance.df)
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
head(importance.df)
library(randomForest)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=100, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=10, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=80, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=100, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
plotTestROC(rf.model2, "随机森林2+Both- Test")
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main="theme")
plot13ROC <- function() {
pre_ran <- predict(rf.model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("1","3"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main="theme")
}
plot13ROC()
plot13ROC <- function() {
pre_ran <- predict(rf.model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("2","3"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main="theme")
}
plot13ROC()
knitr::opts_chunk$set(echo = TRUE)
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[1,2] + confusion[1,3]) / nrow(test)
recall2 <- (confusion[2,1] + confusion[2,2] + confusion[2,3]) / nrow(test)
recall3 <- (confusion[3,1] + confusion[3,2] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
knitr::opts_chunk$set(echo = TRUE)
plotTestROC(tree.over, "Over")
library(C50)
plotTestROC(tree.over, "Over")
library(ggplot2)
# timedelta
ggplot(data = sample.df, aes(x = timedelta, fill=result2)) +
geom_histogram(bins = 100, position = "fill")
# topicNo
ggplot(data = sample.df, aes(x = topicNo, fill=result2)) +
geom_bar(position = position_dodge(width = 0.5))
ggplot(data = sample.df, aes(x = result2)) +
geom_bar(position = position_dodge(width = 0.5))
ggplot(data = sample.df, aes(x = timedelta, y=shares)) +
geom_line()
knitr::opts_chunk$set(echo = TRUE)
mean(abs(train_pred - train$logShares) / train$logShares)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
library(caret)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
library(randomForest)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
head(importance.df)
mean((abs(exp(train_pred) - exp(train$logShares)) / train$shares))
mean((abs(train_pred - train$logShares) / train$logShares))
plotTestROC(rf.model, "随机森林+Both- Test")
plotTestROC <- function(model, theme) {
pre_ran <- predict(model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTrainROC <- function(model, theme) {
pre_ran <- predict(model, newdata=train)
ran_roc <- roc(train$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTestROC(rf.model, "随机森林+Both- Test")
library(pROC)
tableTestBinary <- function(model) {
p <- predict(model, newdata=test)
table(p, test$result2,dnn=c("预测值","真实值"))
}
tableTrainBinary <- function(model) {
p <- predict(model, newdata=train)
table(p, train$result2,dnn=c("预测值","真实值"))
}
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
calResult(rf.model)
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
calResult(rf.model)$recall2
tableTestBinary(rf.model)
calResult(rf.model)$acc
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
print(confusion)
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[1,2] + confusion[1,3]) / nrow(test)
recall2 <- (confusion[2,1] + confusion[2,2] + confusion[2,3]) / nrow(test)
recall3 <- (confusion[3,1] + confusion[3,2] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
print(confusion)
print(confusion[1,1])
print(confusion[2,1])
print(confusion[3,1])
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[1,2] + confusion[1,3]) / nrow(test)
recall2 <- (confusion[2,1] + confusion[2,2] + confusion[2,3]) / nrow(test)
recall3 <- (confusion[3,1] + confusion[3,2] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[2,1] + confusion[3,1]) / nrow(test)
recall2 <- (confusion[1,2] + confusion[2,2] + confusion[3,2]) / nrow(test)
recall3 <- (confusion[1,3] + confusion[2,3] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)
calResult(rf.model)$acc
calResult(rf.model)$recall1
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- confusion[1,1] / (confusion[1,1] + confusion[2,1] + confusion[3,1])
recall2 <- confusion[2,2] /(confusion[1,2] + confusion[2,2] + confusion[3,2])
recall3 <- confusion[3,3] /(confusion[1,3] + confusion[2,3] + confusion[3,3])
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)$recall1
calResult(rf.model)$recall3
calResult(rf.model)$recall2
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
plot13ROC()
dotplot(results)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
head(importance.df)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
set.seed(20021119)
train.cv <- replicate(3, rfcv(train.df, train$result,
cv.fold = 10, step = 1.5), simplify = FALSE)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
set.seed(20021119)
train.cv <- replicate(3, rfcv(x=select(train.df, -c("result2")), y=train.df$result2,
cv.fold = 10, step = 1.5), simplify = FALSE)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
set.seed(20021119)
train.cv <- replicate(3, rfcv(select(train.df, -c("result2")), train.df$result2,
cv.fold = 10, step = 1.5), simplify = FALSE)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
library(dplyr)
set.seed(20021119)
train.cv <- replicate(3, rfcv(select(train.df, -c("result2")), train.df$result2,
cv.fold = 10, step = 1.5), simplify = FALSE)
plot(lm.model)
plotTestROC(tree.over, "Over")
#提取验证结果绘图
train.cv <- data.frame(sapply(train.cv, '[[', 'error.cv'))
train.cv$features <- rownames(train.cv)
train.cv <- reshape2::melt(train.cv, id = 'features')
train.cv$features <- as.numeric(as.character(train.cv$features))
train.cv.mean <- aggregate(train.cv$value, by = list(train.cv$features), FUN = mean)
head(train.cv.mean, 10)
#拟合线图
library(ggplot2)
ggplot(train.cv.mean, aes(Group.1, x)) +
geom_line() +
labs(title = '',x = 'Number of Features', y = 'Cross-validation error')
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
features <- rownames(importance.df[1:1,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count, data=over_sampled3, importance=T, ntree=100, mtry=20)
rf.model2 <- randomForest::randomForest(result2 ~ noun_count, data=both_sampled3, importance=T, ntree=100, mtry=20)
rf.model2 <- randomForest::randomForest(result2 ~ noun_count, data=both_sampled3, importance=T, ntree=100)
rf.model2
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result)
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result2)
features <- rownames(importance.df[1:7,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000, data=both_sampled3, importance=T, ntree=100)
rf.model2
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result2)
features <- rownames(importance.df[1:10,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000 + n_tokens_content + novel.of.title + VWordRatio, data=both_sampled3, importance=T, ntree=100)
rf.model2
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result2)
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
calResult(rf.model2)$recall1
calResult(rf.model2)$recall2
calResult(rf.model2)$recall3
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
features <- rownames(importance.df[1:29,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000 + n_tokens_content + novel.of.title + VWordRatio + average_token_length + global_rate_positive_words + ContentFleschReadingEase + NWordRatio + timedelta + global_sentiment_polarity + global_rate_negative_words + n_tokens_title + is_weekend + SyntaxTree.Height + title_sentiment_polarity + num_self_hrefs + title_subjectivity + num_hrefs + verb_count + global_subjectivity + weekRation + num_imgs + data_channel_is_bus, data=both_sampled3, importance=T, ntree=100)
library(randomForest)
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000 + n_tokens_content + novel.of.title + VWordRatio + average_token_length + global_rate_positive_words + ContentFleschReadingEase + NWordRatio + timedelta + global_sentiment_polarity + global_rate_negative_words + n_tokens_title + is_weekend + SyntaxTree.Height + title_sentiment_polarity + num_self_hrefs + title_subjectivity + num_hrefs + verb_count + global_subjectivity + weekRation + num_imgs + data_channel_is_bus, data=both_sampled3, importance=T, ntree=100, mtry=20)
rf.model2
importance.df <- importance.df[order(importance.df$MeanDecreaseGini,
decreasing = T),]
features <- rownames(importance.df[1:29,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
calResult(rf.model2)$recall1
calResult(rf.model2)$recall2
calResult(rf.model2)$recall3
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
calResult(rf.model2)$acc
calResult(rf.model)$acc
ggplot(data = sample.df, aes(x = shares)) +
geom_histogram() +
xlim(0,10000)
ggplot(data = sample.df, aes(x = shares)) +
geom_histogram() +
xlim(0,6000)
