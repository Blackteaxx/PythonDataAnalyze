data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo
-1,
data = sample.df)
summary(lm.model)
knitr::opts_chunk$set(echo = TRUE)
library(car)
# 检验是否线性
crPlots(lm.model)
knitr::opts_chunk$set(echo = TRUE)
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
lm.model <- lm(shares~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
library(knitr)
library(kableExtra)
library(Hmisc)
library(dplyr)
library(ggplot2)
getwd()
sample.df <- read.csv(file="./Data/News2.csv", header = T,
na.strings=c("","NA","NULL",NULL), sep = ",")
# 查看结果
head(sample.df)
colSums(is.na(sample.df))
sample.df[is.na(sample.df$content.Seg),]
sum(complete.cases(sample.df))
sample.df <- sample.df[-c(21228,29063,30930,35423),]
sample.df[is.na(sample.df$content.Seg),]
colnames(sample.df)
sample.df <- dplyr::select(sample.df, -c("url","title","content",
"n_unique_tokens","n_non_stop_words",
"n_non_stop_unique_tokens",
"num_keywords","content.Seg",
"WikiEntity","title.tokens",
"title.tags"))
str(sample.df)
# 转因子变量
# num_hrefs 133
# num_self_hrefs 59
# num_imgs 91
# num_videos 53
sample.df$data_channel_is_lifestyle <-
as.factor(sample.df$data_channel_is_lifestyle)
sample.df$data_channel_is_entertainment <-
as.factor(sample.df$data_channel_is_entertainment)
sample.df$data_channel_is_bus <-
as.factor(sample.df$data_channel_is_bus)
sample.df$data_channel_is_socmed <-
as.factor(sample.df$data_channel_is_socmed)
sample.df$data_channel_is_tech <-
as.factor(sample.df$data_channel_is_tech)
sample.df$data_channel_is_world <-
as.factor(sample.df$data_channel_is_world)
sample.df$weekday_is_monday <-
as.factor(sample.df$weekday_is_monday)
sample.df$weekday_is_tuesday <-
as.factor(sample.df$weekday_is_tuesday)
sample.df$weekday_is_thursday <-
as.factor(sample.df$weekday_is_thursday)
sample.df$weekday_is_wednesday <-
as.factor(sample.df$weekday_is_wednesday)
sample.df$weekday_is_friday <-
as.factor(sample.df$weekday_is_friday)
sample.df$weekday_is_saturday <-
as.factor(sample.df$weekday_is_saturday)
sample.df$weekday_is_sunday <-
as.factor(sample.df$weekday_is_sunday)
sample.df$is_weekend <-
as.factor(sample.df$is_weekend)
# 大部分全都是发在不是节假日日期的
sample.df$isHoliday <-
as.factor(sample.df$isHoliday)
sample.df$topicNo <-
as.factor(sample.df$topicNo)
# Flesch.Kincaid.Grade.of.Title 122
sample.df$SyntaxTree.Height <-
as.factor(sample.df$SyntaxTree.Height)
# All.Possible.Meanings 这个可能需要归一化
sample.df$noun_count <-
as.factor(sample.df$noun_count)
sample.df$verb_count <-
as.factor(sample.df$verb_count)
# adverb 和 punc偏态都挺严重，可能需要删去
sample.df$adverb_count <-
as.factor(sample.df$adverb_count)
sample.df$punc_count <-
as.factor(sample.df$punc_count)
# 考虑删除
# Comparatives.Count
# Superlatives.Count
# Count.Intensifiers
# Count.Downtoners
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
lm.model <- lm(shares~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
lm.model <- lm(log(shares)~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
lm.model <- lm(log(shares)~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
sample.df$logShares <- log(sample.df$shares)
lm.model <- lm(logShares~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
lm.model <- lm(shares~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday,
data = sample.df)
summary(lm.model)
lm.model <- lm(logShares~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday,
data = sample.df)
summary(lm.model)
lm.model <- lm(shares~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday,
data = sample.df)
summary(lm.model)
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
lm.model <- lm(log(shares)~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday,
data = sample.df)
summary(lm.model)
lm.model <- lm(log(shares)~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday_1,
data = sample.df)
lm.model <- lm(log(shares)~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
library(car)
# 因变量幂次检验
spreadLevelPlot(lm.model)
# 计算预测值
lm.predict <- predict.lm(lm.model)
# 对模型的预测值和因变量都进行对数转换
lm.logpredict <- log(lm.predict)
lm.logoutcome <- log(sample.df$shares)
# 绘制幂次散点图
spreadLevelPlot(lm.logpredict, lm.logoutcome, xlab="Predicted log(shares)",
ylab="Observed log(shares)", main="Spread-Level Plot")
colSums(is.na(sample.df))
sample.df[is.na(sample.df$content.Seg),]
sum(complete.cases(sample.df))
colSums(is.null(sample.df))
colSums(is.na(sample.df))
sample.df[is.na(sample.df$content.Seg),]
sum(complete.cases(sample.df))
lm.model <- lm(log(log(shares))~timedelta + n_tokens_title + n_tokens_content + num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
lm.model <- lm(log(log(shares))~timedelta + n_tokens_title + n_tokens_content +
num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
lm.model <- lm(log(shares)~timedelta + n_tokens_title + n_tokens_content +
num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
lm.model <- lm(log(logShares)~timedelta + n_tokens_title + n_tokens_content +
num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
lm.model <- lm(log(shares)~timedelta + n_tokens_title + n_tokens_content +
num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
# 计算预测值
lm.predict <- predict.lm(lm.model)
# 对模型的预测值和因变量都进行对数转换
lm.logpredict <- log(lm.predict)
lm.logoutcome <- log(sample.df$shares)
# 绘制幂次散点图
spreadLevelPlot(lm.logpredict, lm.logoutcome, xlab="Predicted log(shares)",
ylab="Observed log(shares)", main="Spread-Level Plot")
lm.model <- lm(logShares~timedelta + n_tokens_title + n_tokens_content +
num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df)
summary(lm.model)
# 计算预测值
lm.predict <- predict.lm(lm.model)
# 对模型的预测值和因变量都进行对数转换
lm.logpredict <- lm.predict
lm.logoutcome <- sample.df$logShares
# 绘制幂次散点图
spreadLevelPlot(lm.logpredict, lm.logoutcome, xlab="Predicted log(shares)",
ylab="Observed log(shares)", main="Spread-Level Plot")
# 查找包含无穷大的行或列
which(is.na(sample.df) | is.nan(sample.df) | is.infinite(sample.df))
# 查找包含无穷大的行或列
which(is.na(sample.df$logShares) | is.nan(sample.df$logShares) | is.infinite(sample.df$logShares))
# 替换无穷大为NA
df[df == Inf] <- NA
# 查找包含无穷大的行或列
which(is.na(sample.df$logShares) | is.nan(sample.df$logShares) | is.infinite(sample.df$logShares))
# 查找包含无穷大的行或列
which(is.na(sample.df$logShares) | is.nan(sample.df$logShares) | is.infinite(sample.df$logShares))
# 替换无穷大为NA
sample.df[sample.df == Inf] <- NA
# 删除包含无穷大的行或列
sample.df <- sample.df[, !apply(is.infinite(sample.df), 2, any)]
colSums(is.na(sample.df))
sample.df[is.na(sample.df$content.Seg),]
sum(complete.cases(sample.df))
library(randomForest)
set.seed(20021119)
train.forest <- randomForest(logShares~timedelta + n_tokens_title + n_tokens_content +
num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday-1,
data = sample.df, importance = TRUE, ntree=50)
train.forest
library(randomForest)
set.seed(20021119)
train.forest <- randomForest(logShares~timedelta + n_tokens_title + n_tokens_content +
num_hrefs +
num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo +
Comparatives.Count + Superlatives.Count + Count.Intensifiers +
Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height +
All.Possible.Meanings + noun_count + verb_count + adverb_count +
punc_count + title_subjectivity + title_sentiment_polarity + isHoliday,
data = sample.df, importance = TRUE, ntree=500)
train.forest
importance
#可以根据某种重要性的高低排个序，例如根据“IncNodePurity”指标
importance <- importance[order(importance$IncNodePurity, decreasing = TRUE),]
getwd()
data <- read.csv("./archive/student-mat.csv")
head(data)
str(data)
data$school <- as.factor(data$school)
data$sex <- as.factor(data$sex)
data$address <- as.factor(data$address)
data$famsize <- as.factor(data$famsize)
data$Pstatus <- as.factor(data$Pstatus)
data$Mjob <- as.factor(data$Mjob)
data$Fjob <- as.factor(data$Fjob)
data$reason <- as.factor(data$reason)
data$guardian <- as.factor(data$guardian)
data$schoolsup <- as.factor(data$schoolsup)
data$famsup <- as.factor(data$famsup)
data$paid <- as.factor(data$paid)
data$activities <- as.factor(data$activities)
data$nursery <- as.factor(data$nursery)
data$higher <- as.factor(data$higher)
data$internet <- as.factor(data$internet)
data$romantic <- as.factor(data$romantic)
str(data)
library(dplyr)
data_G1 <- select(data, -c("school", "G2", "G3"))
lm.model <- lm(G1~., data=data_G1)
summary(lm.model)
lm.model <- lm(G1~.-1, data=data_G1)
lm.model
summary(lm.model)
G1.model <- lm(G1~sex+studytime+failures+schoolsup+goout-1,
data=data_G1)
summary(G1.model)
library(car)
plot(G1.model)
AIC(G1.model)
# 检验是否正态
qqPlot(G1.model)
# 检验是否线性
crPlots(G1.model)
# 因变量幂次检验
spreadLevelPlot(G1.model) # 0.46,但是呈水平
# 残差自相关性检验
durbinWatsonTest(G1.model)
# 离群值检验
outlierTest(G1.model)
# 集成检验
influencePlot(G1.model)
data_G1[c(3,79,199,233,249),]
data_G1_2 <- data_G1[-c(3,79,199,233,249),]
G1.model2 <- lm(sqrt(sqrt(G1))~sex+studytime+failures+schoolsup+goout-1,
data=data_G1_2)
summary(G1.model2)
AIC(G1.model2)
AIC(G1.model2)
# 检验是否正态
qqPlot(G1.model2)
# 检验是否线性
crPlots(G1.model2)
# 因变量幂次检验
spreadLevelPlot(G1.model2)
# 残差自相关性检验
durbinWatsonTest(G1.model2)
# 离群值检验
outlierTest(G1.model2)
# 离群值检验
influencePlot(G1.model2)
data_G2 <- select(data, -c("school","G3"))
G2.model <- lm(G2~traveltime+romantic+G1-1, data=data_G2)
summary(G2.model)
AIC(G2.model)
# 检验是否正态
qqPlot(G2.model)
# 检验是否线性
crPlots(G2.model)
# 因变量幂次检验
spreadLevelPlot(G2.model) # 0.46,但是呈水平
# 残差自相关性检验
durbinWatsonTest(G2.model)
# 离群值检验
outlierTest(G2.model)
# 离群值检验
influencePlot(G2.model)
data_G3 <- select(data, -c("school"))
G3.model <- lm(G3~famrel+absences+G2-1, data=data_G3)
summary(G3.model)
AIC(G3.model)
# 检验是否正态
qqPlot(G3.model)
# 检验是否线性
crPlots(G3.model)
# 因变量幂次检验
spreadLevelPlot(G3.model) # 0.46,但是呈水平
# 残差自相关性检验
durbinWatsonTest(G3.model)
# 离群值检验
outlierTest(G3.model)
# 离群值检验
influencePlot(G3.model)
data_G3_2 = data_G3[-c(265,342,141,297,260,311,335,344,334,338),]
G3.model2 <- lm(G3~sex+famrel+G1+G2-1, data=data_G3_2)
summary(G3.model2)
AIC(G3.model2)
# 检验是否正态
qqPlot(G3.model2)
# 检验是否线性
crPlots(G3.model2)
# 因变量幂次检验
spreadLevelPlot(G3.model2) # 0.46,但是呈水平
# 残差自相关性检验
durbinWatsonTest(G3.model2)
# 离群值检验
outlierTest(G3.model2)
# 离群值检验
influencePlot(G3.model2)
index <- sample(c(1,2), nrow(data), replace = T, prob = c(0.7,0.3))
train <- data[index == 1,]
test <- data[index == 2,]
library(randomForest)
set.seed(20021119)
train.forest <- randomForest(G3~., data = train, importance = TRUE)
train.forest
test.predict <- predict(train.forest, newdata = test)
plot(test.predict, test$G3)
summary(train.forest)
importance <- train.forest$importance
importance# 两个值都是越大越好
importance <- as.data.frame(importance)
#可以根据某种重要性的高低排个序，例如根据“IncNodePurity”指标
importance <- importance[order(importance$IncNodePurity, decreasing = TRUE),]
importance
