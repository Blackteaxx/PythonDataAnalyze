n# compare results
dotplot(results)
summary(results)
View(modellist)
modellist
modellist
dotplot(results)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseGini,
decreasing = T),]
head(importance.df)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseGini,
decreasing = T),]
head(importance.df)
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
head(importance.df)
library(randomForest)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=100, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=10, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=80, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title +
n_tokens_content +
num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length +
data_channel_is_lifestyle + data_channel_is_entertainment +
data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech +
data_channel_is_world + is_weekend + topicNo + Comparatives.Count +
Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title +
Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings +
noun_count + verb_count + adverb_count + punc_count + title_subjectivity +
title_sentiment_polarity + isHoliday + ContentFleschReadingEase +
NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity +
global_sentiment_polarity + global_rate_positive_words +
global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
weekRation + twoWeekRation, data=both_sampled3, importance=T,
ntree=100, mtry = 20)
rf.model
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
plotTestROC(rf.model2, "随机森林2+Both- Test")
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main="theme")
plot13ROC <- function() {
pre_ran <- predict(rf.model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("1","3"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main="theme")
}
plot13ROC()
plot13ROC <- function() {
pre_ran <- predict(rf.model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("2","3"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main="theme")
}
plot13ROC()
knitr::opts_chunk$set(echo = TRUE)
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[1,2] + confusion[1,3]) / nrow(test)
recall2 <- (confusion[2,1] + confusion[2,2] + confusion[2,3]) / nrow(test)
recall3 <- (confusion[3,1] + confusion[3,2] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
knitr::opts_chunk$set(echo = TRUE)
plotTestROC(tree.over, "Over")
library(C50)
plotTestROC(tree.over, "Over")
library(ggplot2)
# timedelta
ggplot(data = sample.df, aes(x = timedelta, fill=result2)) +
geom_histogram(bins = 100, position = "fill")
# topicNo
ggplot(data = sample.df, aes(x = topicNo, fill=result2)) +
geom_bar(position = position_dodge(width = 0.5))
ggplot(data = sample.df, aes(x = result2)) +
geom_bar(position = position_dodge(width = 0.5))
ggplot(data = sample.df, aes(x = timedelta, y=shares)) +
geom_line()
knitr::opts_chunk$set(echo = TRUE)
mean(abs(train_pred - train$logShares) / train$logShares)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
library(caret)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
library(randomForest)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
head(importance.df)
mean((abs(exp(train_pred) - exp(train$logShares)) / train$shares))
mean((abs(train_pred - train$logShares) / train$logShares))
plotTestROC(rf.model, "随机森林+Both- Test")
plotTestROC <- function(model, theme) {
pre_ran <- predict(model, newdata=test)
ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTrainROC <- function(model, theme) {
pre_ran <- predict(model, newdata=train)
ran_roc <- roc(train$result2, as.numeric(pre_ran), levels=c("1","2"))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
plotTestROC(rf.model, "随机森林+Both- Test")
library(pROC)
tableTestBinary <- function(model) {
p <- predict(model, newdata=test)
table(p, test$result2,dnn=c("预测值","真实值"))
}
tableTrainBinary <- function(model) {
p <- predict(model, newdata=train)
table(p, train$result2,dnn=c("预测值","真实值"))
}
plotTestROC(rf.model, "随机森林+Both- Test")
plotTrainROC(rf.model, "随机森林+Both- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)
calResult(rf.model)
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
calResult(rf.model)$recall2
tableTestBinary(rf.model)
calResult(rf.model)$acc
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
print(confusion)
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[1,2] + confusion[1,3]) / nrow(test)
recall2 <- (confusion[2,1] + confusion[2,2] + confusion[2,3]) / nrow(test)
recall3 <- (confusion[3,1] + confusion[3,2] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
print(confusion)
print(confusion[1,1])
print(confusion[2,1])
print(confusion[3,1])
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[1,2] + confusion[1,3]) / nrow(test)
recall2 <- (confusion[2,1] + confusion[2,2] + confusion[2,3]) / nrow(test)
recall3 <- (confusion[3,1] + confusion[3,2] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- (confusion[1,1] + confusion[2,1] + confusion[3,1]) / nrow(test)
recall2 <- (confusion[1,2] + confusion[2,2] + confusion[3,2]) / nrow(test)
recall3 <- (confusion[1,3] + confusion[2,3] + confusion[3,3]) / nrow(test)
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)
calResult(rf.model)$acc
calResult(rf.model)$recall1
calResult <- function(model) {
p <- predict(model, newdata=test)
confusion <- table(p, test$result2,dnn=c("预测值","真实值"))
acc <- (confusion[1,1] + confusion[2,2] + confusion[3,3]) / nrow(test)
recall1 <- confusion[1,1] / (confusion[1,1] + confusion[2,1] + confusion[3,1])
recall2 <- confusion[2,2] /(confusion[1,2] + confusion[2,2] + confusion[3,2])
recall3 <- confusion[3,3] /(confusion[1,3] + confusion[2,3] + confusion[3,3])
result <- data.frame(
acc=acc,
recall1=recall1,
recall2=recall2,
recall3=recall3
)
}
calResult(rf.model)$recall1
calResult(rf.model)$recall3
calResult(rf.model)$recall2
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
plot13ROC()
dotplot(results)
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
head(importance.df)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
set.seed(20021119)
train.cv <- replicate(3, rfcv(train.df, train$result,
cv.fold = 10, step = 1.5), simplify = FALSE)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
set.seed(20021119)
train.cv <- replicate(3, rfcv(x=select(train.df, -c("result2")), y=train.df$result2,
cv.fold = 10, step = 1.5), simplify = FALSE)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
set.seed(20021119)
train.cv <- replicate(3, rfcv(select(train.df, -c("result2")), train.df$result2,
cv.fold = 10, step = 1.5), simplify = FALSE)
##交叉验证辅助评估选择特定数量的 Feature
#3 次重复十折交叉验证
library(dplyr)
set.seed(20021119)
train.cv <- replicate(3, rfcv(select(train.df, -c("result2")), train.df$result2,
cv.fold = 10, step = 1.5), simplify = FALSE)
plot(lm.model)
plotTestROC(tree.over, "Over")
#提取验证结果绘图
train.cv <- data.frame(sapply(train.cv, '[[', 'error.cv'))
train.cv$features <- rownames(train.cv)
train.cv <- reshape2::melt(train.cv, id = 'features')
train.cv$features <- as.numeric(as.character(train.cv$features))
train.cv.mean <- aggregate(train.cv$value, by = list(train.cv$features), FUN = mean)
head(train.cv.mean, 10)
#拟合线图
library(ggplot2)
ggplot(train.cv.mean, aes(Group.1, x)) +
geom_line() +
labs(title = '',x = 'Number of Features', y = 'Cross-validation error')
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
features <- rownames(importance.df[1:1,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count, data=over_sampled3, importance=T, ntree=100, mtry=20)
rf.model2 <- randomForest::randomForest(result2 ~ noun_count, data=both_sampled3, importance=T, ntree=100, mtry=20)
rf.model2 <- randomForest::randomForest(result2 ~ noun_count, data=both_sampled3, importance=T, ntree=100)
rf.model2
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result)
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result2)
features <- rownames(importance.df[1:7,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000, data=both_sampled3, importance=T, ntree=100)
rf.model2
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result2)
features <- rownames(importance.df[1:10,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000 + n_tokens_content + novel.of.title + VWordRatio, data=both_sampled3, importance=T, ntree=100)
rf.model2
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result2)
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
calResult(rf.model2)$recall1
calResult(rf.model2)$recall2
calResult(rf.model2)$recall3
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy,
decreasing = T),]
features <- rownames(importance.df[1:29,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000 + n_tokens_content + novel.of.title + VWordRatio + average_token_length + global_rate_positive_words + ContentFleschReadingEase + NWordRatio + timedelta + global_sentiment_polarity + global_rate_negative_words + n_tokens_title + is_weekend + SyntaxTree.Height + title_sentiment_polarity + num_self_hrefs + title_subjectivity + num_hrefs + verb_count + global_subjectivity + weekRation + num_imgs + data_channel_is_bus, data=both_sampled3, importance=T, ntree=100)
library(randomForest)
rf.model2 <- randomForest::randomForest(result2 ~ noun_count + topicNo + data_channel_is_world + data_channel_is_entertainment + Flesch.Kincaid.Grade.of.Title + All.Possible.Meanings + wordRatioIn8000 + n_tokens_content + novel.of.title + VWordRatio + average_token_length + global_rate_positive_words + ContentFleschReadingEase + NWordRatio + timedelta + global_sentiment_polarity + global_rate_negative_words + n_tokens_title + is_weekend + SyntaxTree.Height + title_sentiment_polarity + num_self_hrefs + title_subjectivity + num_hrefs + verb_count + global_subjectivity + weekRation + num_imgs + data_channel_is_bus, data=both_sampled3, importance=T, ntree=100, mtry=20)
rf.model2
importance.df <- importance.df[order(importance.df$MeanDecreaseGini,
decreasing = T),]
features <- rownames(importance.df[1:29,])
formula <- paste0("result2 ~ ", paste(features, collapse = " + "))
formula
calResult(rf.model2)$recall1
calResult(rf.model2)$recall2
calResult(rf.model2)$recall3
calResult(rf.model)$recall1
calResult(rf.model)$recall2
calResult(rf.model)$recall3
calResult(rf.model2)$acc
calResult(rf.model)$acc
ggplot(data = sample.df, aes(x = shares)) +
geom_histogram() +
xlim(0,10000)
ggplot(data = sample.df, aes(x = shares)) +
geom_histogram() +
xlim(0,6000)
knitr::opts_chunk$set(echo = TRUE)
library(ROSE)
twobothsample = ovun.sample(result~ . ,p=0.5, data = train,,method = "over")$data
table(twobothsample$result)
dichotomy.nnet <- nnet(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=twobothsample,maxit=10000,size=8,rang=0.001,linout=F,MaxNWts=7000,decay=4,weights=10/log(twobothsample$shares))
library(nnet)
dichotomy.nnet <- nnet(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=twobothsample,maxit=10000,size=8,rang=0.001,linout=F,MaxNWts=7000,decay=4,weights=10/log(twobothsample$shares))
twobothsample = ovun.sample(result~ . ,p=0.5, data = train,,method = "both")$data
table(twobothsample$result)
library(nnet)
dichotomy.nnet <- nnet(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=twobothsample,maxit=10000,size=8,rang=0.001,linout=F,MaxNWts=7000,decay=4,weights=10/log(twobothsample$shares))
library(nnet)
dichotomy.nnet <- nnet(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=twobothsample,maxit=300,size=8,rang=0.001,linout=F,MaxNWts=7000,decay=4,weights=10/log(twobothsample$shares))
library(nnet)
dichotomy.nnet <- nnet(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=twobothsample,maxit=430,size=8,rang=0.001,linout=F,MaxNWts=7000,decay=4,weights=10/log(twobothsample$shares))
dichotomy.nnet <- nnet(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=twobothsample,maxit=500,size=8,rang=0.001,linout=F,MaxNWts=7000,decay=4,weights=10/log(twobothsample$shares))
pred <- predict(dichotomy.nnet, test, type = "class")
table(predict(dichotomy.nnet, train, type = "class"), train$result,dnn=c("预测值","真实值"))
table(pred, test$result,dnn=c("预测值","真实值"))
getResDown5(dichotomy.nnet)
library(knitr)
library(kableExtra)
library(Hmisc)
library(dplyr)
library(ggplot2)
library(ROSE)
library(DALEX)
library(pROC)
getwd()
getResDown5(dichotomy.nnet)
table(pred, test$result,dnn=c("预测值","真实值"))
nnetpred <- predict(dichotomy.nnet, test, type = "class")
pred <- predict(dichotomy.nnet, test, type = "class")
table(predict(dichotomy.nnet, train, type = "class"), train$result,dnn=c("预测值","真实值"))
t1=table(pred, test$result,dnn=c("预测值","真实值"))
t1
t1[1,1]/(t1[2,1]+t1[1,1])
(t1[1,1]+t1[2,2])/(t1[2,1]+t1[1,1]+t1[2,2]+t1[1,2])
nnetpred <- predict(dichotomy.nnet, test, type = "prob")
nnetpred <- predict(dichotomy.nnet, test, type = "raw")
nnetpred
nnetpred <- predict(dichotomy.nnet, test, type = "raw")
ran_roc <- roc(test$result,as.numeric(nnetpred))
plot(ran_roc,col="black",#颜色
legacy.axes=T,#y轴格式更改
print.auc=T,#显示AUC面积
print.thres=F,#添加截点和95%CI
grid=c(0.2,0.2),grid.col=c("blue","yellow"))#网格线设置
nnetpred <- predict(dichotomy.nnet, test, type = "class")
svmpred = predict(svmmodel, test, type = "class")
library(e1071)
svmmodel <- svm(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=train, kernel = "radial",cost=2^-5,class.weights = c("2" = 1, "1" = 19),gamma=2^-4 ,decay=0.01,probability = TRUE)
#t1=table(predict(svmmodel, train, type = "class"), train$result,dnn=c("预测值","真实值"))
t2=table(predict(svmmodel, test, type = "class"), test$result,dnn=c("预测值","真实值"))
t2
t2[1,1]/(t2[2,1]+t2[1,1])
(t2[1,1]+t2[2,2])/(t2[2,1]+t2[1,1]+t2[2,2]+t2[1,2])
nnetpred <- predict(dichotomy.nnet, test, type = "class")
svmpred = predict(svmmodel, test, type = "class")
svmpred = predict(svmmodel, test, type = "class")
bayespred <- predict(nb.model, test, type = "class")
bayespred <- predict(nb.model, test, type = "class")
treepred = predict(rf.binarymodelDown2, test, type = "class")
rf.binarymodelDown2 <- randomForest(result ~ timedelta + noun_count + average_token_length + topicNo + n_tokens_content + global_subjectivity + wordRatioIn8000 + All.Possible.Meanings + novel.of.title + global_rate_positive_words + VWordRatio + ContentFleschReadingEase + num_hrefs + NWordRatio + global_sentiment_polarity + global_rate_negative_words + Flesch.Kincaid.Grade.of.Title + num_imgs + num_self_hrefs + data_channel_is_world + n_tokens_title + title_sentiment_polarity + data_channel_is_entertainment + title_subjectivity + is_weekend, data = under_sampled4, mtry=10, ntree=300,
importance=T, proximity=T)
library(randomForest)
rf.binarymodelDown2 <- randomForest(result ~ timedelta + noun_count + average_token_length + topicNo + n_tokens_content + global_subjectivity + wordRatioIn8000 + All.Possible.Meanings + novel.of.title + global_rate_positive_words + VWordRatio + ContentFleschReadingEase + num_hrefs + NWordRatio + global_sentiment_polarity + global_rate_negative_words + Flesch.Kincaid.Grade.of.Title + num_imgs + num_self_hrefs + data_channel_is_world + n_tokens_title + title_sentiment_polarity + data_channel_is_entertainment + title_subjectivity + is_weekend, data = under_sampled4, mtry=10, ntree=300,
importance=T, proximity=T)
treepred = predict(rf.binarymodelDown2, test, type = "class")
len <- length(svmpred)
svmclass = c()
bayesclass = c()
nnetclass = c()
treeclass = c()
newclass = c()
for (i in 1:len) {
svmclass = c(svmclass,as.integer(svmpred[i])) #svmclass为svm的预测结果，下面的每一个都是
bayesclass = c(bayesclass,as.integer(bayespred[i]))
nnetclass = c(nnetclass,as.integer(nnetpred[i]))
treeclass = c(treeclass,as.integer(treepred[i]))
}
svmclass[svmclass==1] = 0
svmclass[svmclass==2] = 1
bayesclass[bayesclass==1] = 0
bayesclass[bayesclass==2] = 1
treeclass[treeclass==1] = 1
treeclass[treeclass==2] = 0
for (i in 1:len) {
s = svmclass[i]+bayesclass[i]+nnetclass[i]+treeclass[i]
if(s>2){
newclass = c(newclass,1)
}
else if(s==2){ # 如果是投票平票的情况下，选择相信随机森林模型的预测结果
newclass = c(newclass,treeclass[i])
}
else{
newclass = c(newclass,0)
}
}
newclass = as.factor(newclass)
newt = table(newclass, test$result,dnn=c("预测值","真实值"))
newt
newt[2,1]/(newt[2,1]+newt[1,1])
(newt[2,2]+newt[1,1])/(newt[2,1]+newt[1,1]+newt[2,2]+newt[1,2])
newt
table(nnetclass)
nnetpred <- predict(dichotomy.nnet, test, type = "class")
svmpred = predict(svmmodel, test, type = "class")
nnetpred <- predict(dichotomy.nnet, test, type = "class")
svmpred = predict(svmmodel, test, type = "class")
bayespred <- predict(nb.model, test, type = "class")
treepred = predict(rf.binarymodelDown2, test, type = "class")
len <- length(svmpred)
svmclass = c()
bayesclass = c()
nnetclass = c()
treeclass = c()
newclass = c()
for (i in 1:len) {
svmclass = c(svmclass,as.integer(svmpred[i])) #svmclass为svm的预测结果，下面的每一个都是
bayesclass = c(bayesclass,as.integer(bayespred[i]))
nnetclass = c(nnetclass,as.integer(nnetpred[i]))
treeclass = c(treeclass,as.integer(treepred[i]))
}
#svmclass[svmclass==1] = 0
#svmclass[svmclass==2] = 1
#bayesclass[bayesclass==1] = 0
#bayesclass[bayesclass==2] = 1
#treeclass[treeclass==1] = 1
#treeclass[treeclass==2] = 0
for (i in 1:len) {
s = svmclass[i]+bayesclass[i]+nnetclass[i]+treeclass[i]
if(s>6){
newclass = c(newclass,1)
}
else if(s==6){ # 如果是投票平票的情况下，选择相信随机森林模型的预测结果
newclass = c(newclass,treeclass[i])
}
else{
newclass = c(newclass,0)
}
}
newclass = as.factor(newclass)
newt = table(newclass, test$result,dnn=c("预测值","真实值"))
newt
newt[2,1]/(newt[2,1]+newt[1,1])
(newt[2,2]+newt[1,1])/(newt[2,1]+newt[1,1]+newt[2,2]+newt[1,2])
