---
title: "Test"
author: 
date: '2023-03-19'
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r prepare}
library(knitr)
library(kableExtra)
library(Hmisc)
library(dplyr)
library(ggplot2)
library(ROSE)
library(DALEX)
library(pROC)

getwd()
```

# 0  对结果处理
```{r load}
sample.df <- read.csv(file="E:/paper/大二下学期/数据科学/大作业/News2.csv", header = T,
                     na.strings=c("","NA","NULL",NULL), sep = ",")

# 查看结果
head(sample.df)
```

# 1. 数据预处理
```{r}
head(sample.df)
```

## 1.1 数据描述

### 查找缺失值
```{r 查找缺失值}
colSums(is.na(sample.df))

sample.df[is.na(sample.df$content.Seg),]

sum(complete.cases(sample.df))
```
```{r 删去没什么内容的条目}
sample.df <- sample.df[-c(21228,29063,30930,35423),]
sample.df[is.na(sample.df$content.Seg),]
```


### 描述
```{r 所有列名}
colnames(sample.df)
```


利用Hmisc包中describe进行描述
GMD(Gini mean difference) - 度量变量的离散值
```{r describe查看分布}
desc <- describe(sample.df)

# 将结果存储到文本文件
sink("describe.txt")
cat(capture.output(desc), sep = "\n")
sink()
```

删掉没用的特征
```{r 去除预处理过程中产生的数据}
sample.df <- dplyr::select(sample.df, -c("url","title","content",
                                        "n_unique_tokens","n_non_stop_words",
                                         "n_non_stop_unique_tokens",
                                         "num_keywords","content.Seg",
                                         "WikiEntity","title.tokens",
                                         "title.tags", "kmeans.Temporary"))
```

查看类型
```{r 转因子变量}
str(sample.df)

# 转因子变量
# num_hrefs 133
# num_self_hrefs 59
# num_imgs 91
# num_videos 53

sample.df$data_channel_is_lifestyle <- 
  as.factor(sample.df$data_channel_is_lifestyle)
sample.df$data_channel_is_entertainment <- 
  as.factor(sample.df$data_channel_is_entertainment)
sample.df$data_channel_is_bus <- 
  as.factor(sample.df$data_channel_is_bus)
sample.df$data_channel_is_socmed <- 
  as.factor(sample.df$data_channel_is_socmed)
sample.df$data_channel_is_tech <- 
  as.factor(sample.df$data_channel_is_tech)
sample.df$data_channel_is_world <- 
  as.factor(sample.df$data_channel_is_world)

sample.df$weekday_is_monday <- 
  as.factor(sample.df$weekday_is_monday)
sample.df$weekday_is_tuesday <- 
  as.factor(sample.df$weekday_is_tuesday)
sample.df$weekday_is_thursday <- 
  as.factor(sample.df$weekday_is_thursday)
sample.df$weekday_is_wednesday <- 
  as.factor(sample.df$weekday_is_wednesday)
sample.df$weekday_is_friday <- 
  as.factor(sample.df$weekday_is_friday)
sample.df$weekday_is_saturday <- 
  as.factor(sample.df$weekday_is_saturday)
sample.df$weekday_is_sunday <- 
  as.factor(sample.df$weekday_is_sunday)
sample.df$is_weekend <- 
  as.factor(sample.df$is_weekend)

# 大部分全都是发在不是节假日日期的
sample.df$isHoliday <- 
  as.factor(sample.df$isHoliday)

sample.df$topicNo <- 
  as.factor(sample.df$topicNo)

# Flesch.Kincaid.Grade.of.Title 122

# All.Possible.Meanings 这个可能需要归一化

sample.df$noun_count <- 
  as.factor(sample.df$noun_count)
sample.df$verb_count <- 
  as.factor(sample.df$verb_count)

# adverb 和 punc偏态都挺严重，可能需要删去
sample.df$adverb_count <- 
  as.factor(sample.df$adverb_count)
sample.df$punc_count <- 
  as.factor(sample.df$punc_count)



# 考虑删除
# Comparatives.Count 
# Superlatives.Count 
# Count.Intensifiers 
# Count.Downtoners 


```

归一化
```{r 将歧义归一化}
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

# apply normalization to entire data frame
sample.df$All.Possible.Meanings <- normalize(sample.df$All.Possible.Meanings)
```

### 特征分布与异常值
画分布
```{r 直方图}

GetDistribution <- function(df){
  df = as.data.frame(df)
  variable.No <- ncol(df) 

  for(i in 1:variable.No){
    # 判断该列是否为数值型变量
    if (class(df[,i][1])[1] == "numeric") {
      TmpFileName <- paste("PlotHistFigures/",i,"-",colnames(df)[i],".png",sep="")
      png(file=TmpFileName)
      hist(df[,i],xlim=c(min(na.omit(df[,i])),max(na.omit(df[,i])) )) #get hist for each column
      dev.off()
    }
  }
}

GetDistribution(sample.df)
```

查看预测值分布
```{r shares分布}
hist(sample.df$shares)
boxplot(sample.df$shares)
hist(log(sample.df$shares))
```

画箱线图
```{r 箱线图}
# 绘制箱线图，并保存至文件夹内
for (col in names(sample.df)) {
  if (is.numeric(sample.df[[col]][1])){
      filename <- paste0("boxplots/",col, ".png")
      png(filename)
      boxplot(sample.df[[col]], main = col, horizontal = TRUE)
      dev.off()
  }
}
```

# 2. 回归模型拟合

```{r log转换}
sample.df$logShares <- log(sample.df$shares)
```

```{r 划分测试集与训练集1}
set.seed(20021119)
index <- sample(c(1,2), nrow(sample.df), replace = T, prob = c(0.7, 0.3))
train <- sample.df[index==1,]
test <- sample.df[index==2,]
```

```{r 模型拟合}
# 基准模型
lm.modelbase <- lm(logShares ~ 1, data = train)
summary(lm.modelbase)

lm.model <- lm(logShares~timedelta + n_tokens_title + n_tokens_content +
                 num_hrefs + 
    num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + 
          Comparatives.Count + Superlatives.Count + Count.Intensifiers + 
    Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height + 
    All.Possible.Meanings + noun_count + verb_count + adverb_count + 
    punc_count + title_subjectivity + 
      title_sentiment_polarity+
      isHoliday+ContentFleschReadingEase+NWordRatio+
      VWordRatio+wordRatioIn8000+global_subjectivity+global_sentiment_polarity+
      global_rate_positive_words+global_rate_negative_words+novel.of.title+ 
      dayRatio+threeDayRatio+weekRation+twoWeekRation
      ,
    data = train)
summary(lm.model)
```

```{r MAE}
train_pred_base <- predict(lm.modelbase, newdata = train)
train_pred <- predict(lm.model, newdata = train)

mean((abs(exp(train_pred) - exp(train$logShares)) / train$shares))
mean((abs(exp(train_pred_base) - exp(train$logShares)) / train$shares))
mean((abs(train_pred - train$logShares) / train$logShares))
```
# 3. 分类模型拟合

## 3.1 shares分箱

```{r 二分 Down5}
quantile(sample.df$shares, c(0.05))

range_capture_down <- function(x) {
    if (x >= 0 & x < 584) {
        return(1)
    } else {
      return(2)
    }
}

sample.df$result <- as.factor(sapply(sample.df$shares, range_capture_down))

```

```{r 二分 TOP5}
quantile(sample.df$shares, c(0.95))

range_capture_top <- function(x) {
    if (x > 10800) {
        return(2)
    } else {
      return(1)
    }
}

sample.df$result2 <- as.factor(sapply(sample.df$shares, range_capture_top))


```


### 画几张图
```{r}
library(ggplot2)
# timedelta
  ggplot(data = sample.df, aes(x = timedelta, fill=result)) +
  geom_histogram(bins = 100, position = "fill")

  ggplot(data = sample.df, aes(x = timedelta, y=shares)) +
  geom_line()
  
# topicNo
ggplot(data = sample.df, aes(x = topicNo, fill=result)) +
  geom_bar(position = position_dodge(width = 0.5))

ggplot(data = sample.df, aes(x = result)) +
  geom_bar(position = position_dodge(width = 0.5))
```


## 3.2 定义ROC AUC Confusion
$$ 
TPR = TP / P 
$$

$$
FPR = FP(FalsePositive) / N
$$
目的是取得软分类转硬分类的概率阈值，借以评估分类效果
```{r ROC曲线}
library(pROC)
plotTestROC <- function(model, theme) {
  # 求得概率值
  prob <- predict(model, newdata = test, type = "prob")
  preds <- data.frame(prob)
  
  pred_class <- ifelse(preds$X1 > 0.5, 1, 2)
  preds$class <- pred_class

pre_ran <- predict(model, newdata=test, type = "prob")
  ran_roc <- roc(test$result,as.numeric(preds$X1))

plot(ran_roc,col="black",#颜色
     legacy.axes=T,#y轴格式更改
     print.auc=T,#显示AUC面积
     print.thres=F,#添加截点和95%CI
     grid=c(0.2,0.2),grid.col=c("blue","yellow"))#网格线设置
}


plotTrainROC <- function(model, theme) {
  pre_ran <- predict(model, newdata=train)
  ran_roc <- roc(train$result, as.numeric(pre_ran), levels=c("1","2"))
  plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
```

## 3.3 划分test train

```{r 划分测试集与训练集}
set.seed(20021119)
index <- sample(c(1,2), nrow(sample.df), replace = T, prob = c(0.7, 0.3))
train <- sample.df[index==1,]
test <- sample.df[index==2,]
```


## 3.4 处理不平衡
[不平衡处理方法](https://www.zhihu.com/question/324187407)
[ROSE](https://zhuanlan.zhihu.com/p/24826792)

### 3.4.2 二分的不平衡处理-Down5

#### 定义一些函数
```{r 结果函数定义以及采样过程函数定义}
# 这边修改C5.0的formula，取消timedelta +
library(ROSE)
library(C50)
library(dplyr)

train.df <- dplyr::select(train, -c("Date", "HolidayName"))
table(train.df$result)
table(train.df$result)

# 混淆矩阵
tableDown5 <- function(model) {
  p <- predict(model, newdata = test)
  t <- table(p, test$result, dnn = c("预测值", "真实值"))
  # 有可能出现上下颠倒的情况
  if (rownames(t)[1] == "2") {
    t <- t[c(2,1), ]
  }
  return(t)
}

# 准确率和召回率
getScoresDown5 <- function(t) {
  acc <- (t[1,1] + t[2,2]) / sum(t)
  recall1 <- t[1,1] / (t[1,1] + t[2,1])
  recall2 <- t[2,2] / (t[1,2] + t[2,2])
  return (c(acc, recall1, recall2))
}

# AUC值
getAUCDown5 <- function(model) {
  pre_ran <- predict(model, newdata=test)
  t <- table(pre_ran, test$result, dnn = c("预测值", "真实值"))
  
  # 有可能出现上下颠倒的情况
  if (rownames(t)[1] == "2") {
    ran_roc <- roc(test$result,as.numeric(pre_ran), levels=c("2","1"))
    auc_v <- auc(ran_roc)
    return(auc_v)
  } else {
    ran_roc <- roc(test$result,as.numeric(pre_ran), levels=c("1","2"))
    auc_v <- auc(ran_roc)
    return(auc_v)
  }
}

# 合并结果
getResDown5 <- function(model) {
  auc <- getAUCDown5(model)
  t <- tableDown5(model)
  scores <- getScoresDown5(t)
  return(c(scores, auc))
}

# 得出四种采样的模型分值
getScoresDown5InBalancedExec <- function(modelu, modelo, modelb, modelr) {
  res_under <- getResDown5(modelu)
  res_over <- getResDown5(modelo)
  res_both <- getResDown5(modelb)
  res_rose <- getResDown5(modelr)
  colname <- c("Acc", "Recall1", "Recall2", "AUC")
  rowname <- c("under", "over", "both", "rose")
  res.df <- data.frame()
  res.df <- rbind(res.df, res_under, res_over, res_both, res_rose)
  colnames(res.df) <- colname
  rownames(res.df) <- rowname
  return(res.df)
}

# 得出结果数据框
tempfun <- function(over, both, under, rose) {
  
    #input:four balanced data
    #output:C50 model scores: recallPos recallNeg Accuracy
  
  tree.over <-  C5.0(result ~ timedelta +n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=over)

tree.under <-  C5.0(result ~ timedelta +n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=under)

tree.both <-  C5.0(result ~ timedelta +n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=both)

tree.rose <-  C5.0(result ~ timedelta +n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=rose)

  # 得到指标
  return(getScoresDown5InBalancedExec(tree.under, tree.over, tree.both, tree.rose))
  
}
```

#### 不做不平衡处理会发生什么？
```{r}
library(C50)
tree <-  C5.0(result ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=train)

getResDown5(tree)
```
#### 找比较好的不平衡方法和p值
```{r}
model.list1 <- list()

# 我直接开始都搜一遍
for (prob in seq(from=0.2,to=0.8,by=0.02)) {
  # balance
  over_sampled4 <- ovun.sample(result ~ ., data = train.df, method = "over", p=prob)$data
  both_sampled4 <- ovun.sample(result ~ ., data = train.df, method = "both", p=prob)$data
  under_sampled4 <- ovun.sample(result ~ ., data = train.df, method = "under", p=prob)$data
  rose_sampled4 <- ROSE(result ~ ., data = train.df, p=prob)$data
  
  # 拟合,并得出准确率和召回率
  res.df <- tempfun(over_sampled4, both_sampled4, under_sampled4, rose_sampled4)
  
  key <- toString(prob)
  model.list1[[key]] <- res.df
  print(paste0("训练完成:", prob))
} 
```

```{r 查看探索结果}
# 遍历 my_list 列表及其索引
cur.df <- model.list1[["0.2"]]
result.df <- data.frame(cur.df$AUC, rownames(cur.df), c("0.2","0.2","0.2","0.2"))
colnames(result.df) <- c("AUC", "METHOD", "P")



for (prob in seq(from=0.22, to=0.8, by=0.02)) {
  key <- toString(prob)
  cur.df <- model.list1[[key]]
  
  # 创建临时数据框
  temp <- data.frame(cur.df$AUC, rownames(cur.df), c(key,key,key,key))
  colnames(temp) <- c("AUC", "METHOD", "P")
  
  # 将临时数据框与 result.df 合并
  result.df <- rbind(result.df, temp)
}

# 将 P 列转换为因子类型
result.df$P <- as.factor(result.df$P)
result.df$METHOD <- as.factor(result.df$METHOD)

# 拆分 METHOD 列为四个不同的列

library(ggplot2)

result.df

# 创建 ggplot 对象
p <- ggplot(result.df, aes(x = P, y = AUC, group=METHOD, color = METHOD)) + geom_line()

p
```

```{r 选择欠采样}
set.seed(20021119)
# 最终发现p=0.46 的欠采样，效果比较令人满意
 under_sampled4 <- ovun.sample(result ~ ., data = train.df, method = "under", p=0.46)$data
```

评估
```{r}
library(C50)
tree.under <-  C5.0(result ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=under_sampled4)

```

```{r 查看结果}
getResDown5(tree.under)
```

### 3.4.3 二分的不平衡处理-Top5

```{r}
library(ROSE)
library(C50)
library(dplyr)
table(train$result2)
```


```{r}
over_sampled5 <- ovun.sample(result2 ~ ., data = train, method = "over", p=0.5)$data
```


 
## 3.5 二分类-Down 5

### 1 随机森林

Generated by HT

```{r}
library(randomForest)

rf.binarymodelDown <- randomForest::randomForest(result ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=train, importance=T, 
    ntree=400, mtry = 20)

rf.binarymodelDown
getResDown5(rf.binarymodelDown)
plotTestROC(rf.binarymodelDown,"")
```

```{r 随机森林}
library(randomForest)

rf.binarymodelDownWithOutT <- randomForest::randomForest(result ~  n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=under_sampled4, importance=T, 
    ntree=500, mtry = 40)

# 带时间的模型
rf.binarymodelDown <- randomForest::randomForest(result ~  timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=under_sampled4, importance=T, 
    ntree=400, mtry = 25)

rf.binarymodelDown

# 这边不知道为什么会抽风，去再搞一下不平衡就会好
getResDown5(rf.binarymodelDown)
getResDown5(rf.binarymodelDownWithOutT)

plot(rf.binarymodelDown)

plotTestROC(rf.binarymodelDownWithOutT,"")
plotTestROC(rf.binarymodelDown,"")
```

#### 调参
[随机森林调参](https://zhuanlan.zhihu.com/p/352793220)
```{r}
train.df <- select(under_sampled4, -c("result2", "shares", "result"))
```

##### 调整mtry 和 ntree
3次10折
```{r}
library(caret)
if(file.exists('rda/rf_manual1.rda')){
  results <- readRDS("rda/rf_manual1.rda")
} else {
  # Manual Search
  trControl <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")

  # 用默认值固定mtry
  tunegrid <- expand.grid(mtry=c(5,10,15,20,25,30))

  # 定义模型列表，存储每一个模型评估结果
  modellist <- list()

  # 交叉验证，调参，耗时很久，同时误差率没啥参考价值(好吧，可能有点价值)，别跑
  for (ntree in c(100,150,200,250,300,350,400,450,500)) {
      fit <- train(x=train.df, y=under_sampled4$result, method="rf", 
                   metric="Accuracy", tuneGrid=tunegrid, 
                   trControl=trControl, ntree=ntree)
      key <- toString(ntree)
      modellist[[key]] <- fit
      print(paste0("训练完成:", ntree))
  }
  results <- resamples(modellist)
  modellist
  saveRDS(results, "rda/rf_manual1.rda")
}
summary(results)
dotplot(results)

```

##### 选择特征
```{r 交叉验证}
##交叉验证辅助评估选择特定数量的 Feature
#5 次重复十折交叉验证
library(dplyr)
set.seed(20021119)
train.cv <- replicate(5,rfcv(train.df ,
                             under_sampled4$result,
                             cv.fold = 10, step = 1.5), simplify = FALSE)
```

```{r 提取特征与准确率}
#提取验证结果绘图
train.cv <- data.frame(sapply(train.cv, '[[', 'error.cv'))
train.cv$features <- rownames(train.cv)
train.cv <- reshape2::melt(train.cv, id = 'features')
train.cv$features <- as.numeric(as.character(train.cv$features))
 
train.cv.mean <- aggregate(train.cv$value, by = list(train.cv$features), FUN = mean)
head(train.cv.mean, 10)
```


```{r 画图}
#拟合线图
library(ggplot2)
 
ggplot(train.cv.mean, aes(Group.1, x)) +
  geom_line() +
labs(title = '',x = 'Number of Features', y = 'Cross-validation error')
```

```{r 特征排名}
varImpPlot(rf.binarymodelDown, n.var = 30, main = "Top 30 - Variable Importance")

importance.df <- data.frame(importance(rf.binarymodelDown), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseGini, 
                                   decreasing = T),]
head(importance.df)
```


```{r 根据GINI选择前25个}
importance.df <- importance.df[order(importance.df$MeanDecreaseGini, 
                                   decreasing = T),]
features <- rownames(importance.df[1:25,])

importance.df

formula <- paste0("result ~ ", paste(features, collapse = " + "))

formula
```

#### 结果呈现
```{r 最终的结果}
library(randomForest)
rf.binarymodelDown2 <- randomForest(result ~ timedelta + noun_count + average_token_length + topicNo + n_tokens_content + global_subjectivity + wordRatioIn8000 + All.Possible.Meanings + novel.of.title + global_rate_positive_words + VWordRatio + ContentFleschReadingEase + num_hrefs + NWordRatio + global_sentiment_polarity + global_rate_negative_words + Flesch.Kincaid.Grade.of.Title + num_imgs + num_self_hrefs + data_channel_is_world + n_tokens_title + title_sentiment_polarity + data_channel_is_entertainment + title_subjectivity + is_weekend, data = under_sampled4, mtry=10, ntree=300,
                                    importance=T, proximity=T)

# 这个结果会抽风
getResDown5(rf.binarymodelDown)
getResDown5(rf.binarymodelDown2)

plotTestROC(rf.binarymodelDown2)
plotTestROC(rf.binarymodelDown)


plot(rf.binarymodelDown2)
```


### 2 SVM

Generated by ZY

```{r SVM 寻找最优}
library(e1071)
set.seed(20021119)
cl=seq(-5,5,1)
gl=seq(-5,5,1)
for(i in cl){
  for(j in gl){
    svmmodel <- svm(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=train, kernel = "radial",cost=2^i,class.weights = c("2" = 1, "1" = 19),gamma=2^j)
  #t1=table(predict(svmmodel, train, type = "class"), train$result,dnn=c("预测值","真实值"))
  t2=table(predict(svmmodel, test, type = "class"), test$result,dnn=c("预测值","真实值"))
  zhl = t2[1,1]/(t2[2,1]+t2[1,1])
  zql = t2[2,2]/(t2[1,2]+t2[2,2])
  print(c(i,j,zhl,zql))
  if(zhl>0.65 & zql>0.7){
    print("this")
  }
  else if(zhl<0.2){
    break;
  }
  }
}
```


```{r svm训练与预测}
library(e1071)
svmmodel <- svm(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=train, kernel ="radial",cost=2^-5,class.weights = c("1" = 19, "2" = 1),gamma=2^-4 ,decay=0.01,probability = TRUE)
  #t1=table(predict(svmmodel, train, type = "class"), train$result,dnn=c("预测值","真实值"))
 t2=table(predict(svmmodel, test, type = "class"), test$result,dnn=c("预测值","真实值"))
 t2
 t2[1,1]/(t2[2,1]+t2[1,1])
(t2[1,1]+t2[2,2])/(t2[2,1]+t2[1,1]+t2[2,2]+t2[1,2])
```

```{r svm roc}
library(pROC)
plotTestROCSVM <- function(model, theme) {
  # 求得概率值
  output <- predict(svmmodel, newdata=test, probability=T)
prob <- attr(output, "probabilities")[,'1'] 

pre_ran <- predict(model, newdata=test, type = "prob")
  ran_roc <- roc(test$result,prob)

plot(ran_roc,col="black",#颜色
     legacy.axes=T,#y轴格式更改
     print.auc=T,#显示AUC面积
     print.thres=F,#添加截点和95%CI
     grid=c(0.2,0.2),grid.col=c("blue","yellow"))#网格线设置
}
plotTestROCSVM(svmmodel,"SVM")
getResDown5(svmmodel)
```
### 3 NNET
```{r 二分nnet}
library(nnet)
library(ROSE)
twobothsample = ovun.sample(result~ . ,p=0.5, data = train,,method = "both")$data
table(twobothsample$result)
dichotomy.nnet <- nnet(result ~ is_weekend + data_channel_is_world + data_channel_is_entertainment + data_channel_is_socmed + num_imgs + timedelta + n_tokens_content + num_hrefs + global_rate_positive_words + average_token_length + global_subjectivity + global_sentiment_polarity + data_channel_is_tech + data_channel_is_bus + num_self_hrefs + global_rate_negative_words + num_videos + title_sentiment_polarity + title_subjectivity, data=twobothsample,maxit=10000,size=8,rang=0.001,linout=F,MaxNWts=7000,decay=4,weights=10/log(twobothsample$shares))
t1=table(pred, test$result,dnn=c("预测值","真实值"))
 t1
 t1[1,1]/(t1[2,1]+t1[1,1])
(t1[1,1]+t1[2,2])/(t1[2,1]+t1[1,1]+t1[2,2]+t1[1,2])
```

### 4 NB
```{r}
library(e1071)
nb.model <- naiveBayes(result ~ n_tokens_title + 
                             n_tokens_content + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=train, laplace = 0,  subset, na.action = na.pass)

nb.pred <- predict(object=nb.model,newdata =test, type="raw")
# nb.pred[,1]
# getResDown5(nb.model)

plotTestROCNaiveBayes <- function(model, theme) {
  # 求得概率值
  output <- predict(model, newdata=test, type="raw")
  prob <- output[,1]

  ran_roc <- roc(test$result,prob)

plot(ran_roc,col="black",#颜色
     legacy.axes=T,#y轴格式更改
     print.auc=T,#显示AUC面积
     print.thres=F,#添加截点和95%CI
     grid=c(0.2,0.2),grid.col=c("blue","yellow"))#网格线设置
}

plotTestROCNaiveBayes(nb.model, "")
save.image()
```
### 4 NN
```{r 采样方法选择}
library(ROSE)
twobothsample = ovun.sample(result~ . ,p=0.5, data = train,,method = "both")$data
table(twobothsample$result)
```
### 5 投票
```{r}
nnetpred <- predict(dichotomy.nnet, test, type = "class")
svmpred = predict(svmmodel, test, type = "class")
bayespred <- predict(nb.model, test, type = "class")
treepred = predict(rf.binarymodelDown2, test, type = "class")
len <- length(svmpred)
svmclass = c()
bayesclass = c()
nnetclass = c()
treeclass = c()
newclass = c()

for (i in 1:len) {
  svmclass = c(svmclass,as.integer(svmpred[i])) #svmclass为svm的预测结果，下面的每一个都是
  bayesclass = c(bayesclass,as.integer(bayespred[i]))
  nnetclass = c(nnetclass,as.integer(nnetpred[i]))
  treeclass = c(treeclass,as.integer(treepred[i]))
}

svmclass[svmclass==1] = 0
svmclass[svmclass==2] = 1
bayesclass[bayesclass==1] = 0
bayesclass[bayesclass==2] = 1
treeclass[treeclass==1] = 1
treeclass[treeclass==2] = 0

for (i in 1:len) {
  s = svmclass[i]+bayesclass[i]+nnetclass[i]+treeclass[i]
  if(s>2){
    newclass = c(newclass,1)
  }
 else if(s==2){ # 如果是投票平票的情况下，选择相信随机森林模型的预测结果
    newclass = c(newclass,treeclass[i])
}
  else{
    newclass = c(newclass,0)
  }
}
t = test$result
t[t==1]=0
t[t==2]=1
newclass = as.factor(newclass)
newt = table(newclass, t,dnn=c("预测值","真实值"))
newt
newt[1,1]/(newt[2,1]+newt[1,1])
(newt[2,2]+newt[1,1])/(newt[2,1]+newt[1,1]+newt[2,2]+newt[1,2])
```
```{r}
table(newclass)
table(test$result)
```


## 3.6 二分类-Top 5
```{r}
library(randomForest)

rf.binarymodelTop <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=over_sampled5, importance=T, 
    ntree=500, mtry = 20)

rf.binarymodelTop
plot(rf.binarymodelTop)
```
```{r}
tableDown5(rf.binarymodelTop)
getResDown5(rf.binarymodelTop)
```


# 4.变量解释

https://zhuanlan.zhihu.com/p/354108603?utm_id=0

http://e.betheme.net/article/show-1266723.aspx?action=onClick




```{r}
library(iml)
library(randomForest)
library(partykit)
library(glmnet)
```
```{r}
test.df <- dplyr::select(test, -c("result", "result2"))
```

## ALE
```{r}
predictor <- Predictor$new(rf.binarymodelDown2, data = test.df, y = test$result)

plotALE <- function(feature) {
  ALE <- FeatureEffects$new(predictor, feature=feature)
  plot(ALE)
}
```

```{r}
plotALE("average_token_length")
```

```{r}
plotALE("n_tokens_content")
```
```{r}
plotALE("global_subjectivity")
```

```{r}
plotALE("wordRatioIn8000")
```

```{r}
plotALE("All.Possible.Meanings")
```
```{r}
plotALE("novel.of.title")
```

```{r}
plotALE("global_rate_positive_words")
```
```{r}
plotALE("VWordRatio")
```
```{r}
plotALE("ContentFleschReadingEase")
```
```{r}
plotALE("num_hrefs")
```
```{r}
plotALE("NWordRatio")
```
```{r}
plotALE("global_sentiment_polarity")
```
```{r}
plotALE("global_rate_negative_words")
```

```{r}
plotALE("Flesch.Kincaid.Grade.of.Title")
```
```{r}
plotALE("num_imgs")
```
```{r}
plotALE("num_self_hrefs")
```
```{r}
plotALE("title_sentiment_polarity")
```
```{r}
plotALE("title_subjectivity")
```

## LIME
```{r}
# LIME使用距离度量来计算加权glm的接近权值
# 使用LocalModel方法解释数据集的实例:
lime.explain <- LocalModel$new(predictor, x.interest = test[3000,], k = 10)
lime.explain
lime.explain$results
plot(lime.explain)
```


## PDP

因为正负类趋势已知，所以很难用PDP，改用上文的ALE

```{r}
library(DALEX)
```


```{r}
test$response <- ifelse(test$result == 1, "Positive", "Negative")

test$response <- as.factor(test$response)

explainer_rf <- DALEX::explain(rf.binarymodelDown2, label = "rf", data = test, y = test$response)

plotPDPPos <- function(variable) {
  pdp_rf1<-model_profile(explainer_rf,
                          variable = variable,
                          type = "partial",
                      target="Positive")
  plot(pdp_rf1)
}

plotPDPNeg <- function(variable) {
  pdp_rf1<-model_profile(explainer_rf,
                          variable = variable,
                          type = "partial",
                      target="Negative")
  plot(pdp_rf1)
}

plotPDPPos("title_subjectivity")
plotPDPNeg("title_subjectivity")
save.image()
```

