---
title: "Test"
author: 
date: '2023-03-19'
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r prepare}
library(knitr)
library(kableExtra)
library(Hmisc)
library(dplyr)
library(ggplot2)

getwd()
```

# 0  对结果处理
```{r load}
sample.df <- read.csv(file="./Data/News2.csv", header = T,
                     na.strings=c("","NA","NULL",NULL), sep = ",")


# 查看结果
head(sample.df)

```

# 1. 数据预处理
```{r}
head(sample.df)
```

## 1.1 数据描述

### 查找缺失值
```{r 查找缺失值}
colSums(is.na(sample.df))

sample.df[is.na(sample.df$content.Seg),]

sum(complete.cases(sample.df))
```
```{r 删去没什么内容的条目}
sample.df <- sample.df[-c(21228,29063,30930,35423),]
sample.df[is.na(sample.df$content.Seg),]
```


### 描述
```{r 所有列名}
colnames(sample.df)
```


利用Hmisc包中describe进行描述
GMD(Gini mean difference) - 度量变量的离散值
```{r describe查看分布}
desc <- describe(sample.df)

# 将结果存储到文本文件
sink("describe.txt")
cat(capture.output(desc), sep = "\n")
sink()
```

删掉没用的特征
```{r 去除预处理过程中产生的数据}
sample.df <- dplyr::select(sample.df, -c("url","title","content",
                                        "n_unique_tokens","n_non_stop_words",
                                         "n_non_stop_unique_tokens",
                                         "num_keywords","content.Seg",
                                         "WikiEntity","title.tokens",
                                         "title.tags", "kmeans.Temporary"))


```

查看类型
```{r 转因子变量}
str(sample.df)

# 转因子变量
# num_hrefs 133
# num_self_hrefs 59
# num_imgs 91
# num_videos 53

sample.df$data_channel_is_lifestyle <- 
  as.factor(sample.df$data_channel_is_lifestyle)
sample.df$data_channel_is_entertainment <- 
  as.factor(sample.df$data_channel_is_entertainment)
sample.df$data_channel_is_bus <- 
  as.factor(sample.df$data_channel_is_bus)
sample.df$data_channel_is_socmed <- 
  as.factor(sample.df$data_channel_is_socmed)
sample.df$data_channel_is_tech <- 
  as.factor(sample.df$data_channel_is_tech)
sample.df$data_channel_is_world <- 
  as.factor(sample.df$data_channel_is_world)

sample.df$weekday_is_monday <- 
  as.factor(sample.df$weekday_is_monday)
sample.df$weekday_is_tuesday <- 
  as.factor(sample.df$weekday_is_tuesday)
sample.df$weekday_is_thursday <- 
  as.factor(sample.df$weekday_is_thursday)
sample.df$weekday_is_wednesday <- 
  as.factor(sample.df$weekday_is_wednesday)
sample.df$weekday_is_friday <- 
  as.factor(sample.df$weekday_is_friday)
sample.df$weekday_is_saturday <- 
  as.factor(sample.df$weekday_is_saturday)
sample.df$weekday_is_sunday <- 
  as.factor(sample.df$weekday_is_sunday)
sample.df$is_weekend <- 
  as.factor(sample.df$is_weekend)

# 大部分全都是发在不是节假日日期的
sample.df$isHoliday <- 
  as.factor(sample.df$isHoliday)

sample.df$topicNo <- 
  as.factor(sample.df$topicNo)

# Flesch.Kincaid.Grade.of.Title 122

# All.Possible.Meanings 这个可能需要归一化

sample.df$noun_count <- 
  as.factor(sample.df$noun_count)
sample.df$verb_count <- 
  as.factor(sample.df$verb_count)

# adverb 和 punc偏态都挺严重，可能需要删去
sample.df$adverb_count <- 
  as.factor(sample.df$adverb_count)
sample.df$punc_count <- 
  as.factor(sample.df$punc_count)



# 考虑删除
# Comparatives.Count 
# Superlatives.Count 
# Count.Intensifiers 
# Count.Downtoners 


```

归一化
```{r 将歧义归一化}
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

# apply normalization to entire data frame
sample.df$All.Possible.Meanings <- normalize(sample.df$All.Possible.Meanings)
```

### 特征分布与异常值
画分布
```{r 直方图}

GetDistribution <- function(df){
  df = as.data.frame(df)
  variable.No <- ncol(df) 

  for(i in 1:variable.No){
    # 判断该列是否为数值型变量
    if (class(df[,i][1])[1] == "numeric") {
      TmpFileName <- paste("PlotHistFigures/",i,"-",colnames(df)[i],".png",sep="")
      png(file=TmpFileName)
      hist(df[,i],xlim=c(min(na.omit(df[,i])),max(na.omit(df[,i])) )) #get hist for each column
      dev.off()
    }
  }
}

GetDistribution(sample.df)
```

查看预测值分布
```{r shares分布}
hist(sample.df$shares)
boxplot(sample.df$shares)
hist(log(sample.df$shares))
```

画箱线图
```{r 箱线图}
# 对于集中于一条线的，例如kw_avg_avg那种，一般是有严重的偏态，一般取对数
# 绘制箱线图，并保存至文件夹内
for (col in names(sample.df)) {
  if (is.numeric(sample.df[[col]][1])){
      filename <- paste0("boxplots/",col, ".png")
      png(filename)
      boxplot(sample.df[[col]], main = col, horizontal = TRUE)
      dev.off()
  }
}
```


## 2. 回归模型拟合

```{r log转换}
sample.df$logShares <- log(sample.df$shares)
```

```{r 划分测试集与训练集}
set.seed(333)
index <- sample(c(1,2), nrow(sample.df), replace = T, prob = c(0.7, 0.3))
train <- sample.df[index==1,]
test <- sample.df[index==2,]
```

```{r 模型拟合}
lm.model <- lm(logShares~timedelta + n_tokens_title + n_tokens_content +
                 num_hrefs + 
    num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + 
          Comparatives.Count + Superlatives.Count + Count.Intensifiers + 
    Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height + 
    All.Possible.Meanings + noun_count + verb_count + adverb_count + 
    punc_count + title_subjectivity + 
      title_sentiment_polarity+
      isHoliday+ContentFleschReadingEase+NWordRatio+
      VWordRatio+wordRatioIn8000+global_subjectivity+global_sentiment_polarity+
      global_rate_positive_words+global_rate_negative_words+novel.of.title+ 
      dayRatio+threeDayRatio+weekRation+twoWeekRation
      -1,
    data = train)
summary(lm.model)
```

```{r MAE}
train_pred <- predict(lm.model, newdata = train)
mean(abs(exp(train_pred) - exp(train$logShares)))
test_pred <- predict(lm.model, newdata = test)
mean(abs(exp(test_pred) - exp(test$logShares)))
```

# 3. 分类模型拟合

## shares分箱

```{r 二分}
range_capture <- function(x) {
    if (x >= 0 & x < 1400) {
        return(0)
    } else {
      return(1)
    }
}

sample.df$result <- as.factor(sapply(sample.df$shares, range_capture))

```

## 划分test train

```{r 划分测试集与训练集}
set.seed(20021119)
index <- sample(c(1,2), nrow(sample.df), replace = T, prob = c(0.7, 0.3))
train <- sample.df[index==1,]
test <- sample.df[index==2,]
```

## 随机森林

```{r 随机森林}
library(randomForest)

rf.model <- randomForest::randomForest(result ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title + dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=train, importance=T, ntree=450)

rf.model
```

### 选择特征
```{r}
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")
```


```{r}
library(caret)

# 构建控制参数
ctrl <- trainControl(method = "cv", number = 5, search = "grid")

grid <- expand.grid(mtry = 10:43)

# 训练模型
model <- caret::train(result ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title + dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=train,
    method = "rf", trControl = ctrl, tuneGrid = grid, ntree=500)

# 输出最优参数
print(paste0("Best Parameters: ", model$bestTune))

# 输出准确率和召回率
print(model$results[, c("ntree", "mtry", "Accuracy", "Recall")])


```
