---
title: "Test"
author: 
date: '2023-03-19'
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r prepare}
library(knitr)
library(kableExtra)
library(Hmisc)
library(dplyr)
library(ggplot2)

getwd()
```

# 0  对结果处理
```{r load}
sample.df <- read.csv(file="./Data/News2.csv", header = T,
                     na.strings=c("","NA","NULL",NULL), sep = ",")


# 查看结果
head(sample.df)
```

# 1. 数据预处理
```{r}
head(sample.df)
```

## 1.1 数据描述

### 查找缺失值
```{r 查找缺失值}
colSums(is.na(sample.df))

sample.df[is.na(sample.df$content.Seg),]

sum(complete.cases(sample.df))
```
```{r 删去没什么内容的条目}
sample.df <- sample.df[-c(21228,29063,30930,35423),]
sample.df[is.na(sample.df$content.Seg),]
```


### 描述
```{r 所有列名}
colnames(sample.df)
```


利用Hmisc包中describe进行描述
GMD(Gini mean difference) - 度量变量的离散值
```{r describe查看分布}
desc <- describe(sample.df)

# 将结果存储到文本文件
sink("describe.txt")
cat(capture.output(desc), sep = "\n")
sink()
```

删掉没用的特征
```{r 去除预处理过程中产生的数据}
sample.df <- dplyr::select(sample.df, -c("url","title","content",
                                        "n_unique_tokens","n_non_stop_words",
                                         "n_non_stop_unique_tokens",
                                         "num_keywords","content.Seg",
                                         "WikiEntity","title.tokens",
                                         "title.tags", "kmeans.Temporary"))


```

查看类型
```{r 转因子变量}
str(sample.df)

# 转因子变量
# num_hrefs 133
# num_self_hrefs 59
# num_imgs 91
# num_videos 53

sample.df$data_channel_is_lifestyle <- 
  as.factor(sample.df$data_channel_is_lifestyle)
sample.df$data_channel_is_entertainment <- 
  as.factor(sample.df$data_channel_is_entertainment)
sample.df$data_channel_is_bus <- 
  as.factor(sample.df$data_channel_is_bus)
sample.df$data_channel_is_socmed <- 
  as.factor(sample.df$data_channel_is_socmed)
sample.df$data_channel_is_tech <- 
  as.factor(sample.df$data_channel_is_tech)
sample.df$data_channel_is_world <- 
  as.factor(sample.df$data_channel_is_world)

sample.df$weekday_is_monday <- 
  as.factor(sample.df$weekday_is_monday)
sample.df$weekday_is_tuesday <- 
  as.factor(sample.df$weekday_is_tuesday)
sample.df$weekday_is_thursday <- 
  as.factor(sample.df$weekday_is_thursday)
sample.df$weekday_is_wednesday <- 
  as.factor(sample.df$weekday_is_wednesday)
sample.df$weekday_is_friday <- 
  as.factor(sample.df$weekday_is_friday)
sample.df$weekday_is_saturday <- 
  as.factor(sample.df$weekday_is_saturday)
sample.df$weekday_is_sunday <- 
  as.factor(sample.df$weekday_is_sunday)
sample.df$is_weekend <- 
  as.factor(sample.df$is_weekend)

# 大部分全都是发在不是节假日日期的
sample.df$isHoliday <- 
  as.factor(sample.df$isHoliday)

sample.df$topicNo <- 
  as.factor(sample.df$topicNo)

# Flesch.Kincaid.Grade.of.Title 122

# All.Possible.Meanings 这个可能需要归一化

sample.df$noun_count <- 
  as.factor(sample.df$noun_count)
sample.df$verb_count <- 
  as.factor(sample.df$verb_count)

# adverb 和 punc偏态都挺严重，可能需要删去
sample.df$adverb_count <- 
  as.factor(sample.df$adverb_count)
sample.df$punc_count <- 
  as.factor(sample.df$punc_count)



# 考虑删除
# Comparatives.Count 
# Superlatives.Count 
# Count.Intensifiers 
# Count.Downtoners 


```

归一化
```{r 将歧义归一化}
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

# apply normalization to entire data frame
sample.df$All.Possible.Meanings <- normalize(sample.df$All.Possible.Meanings)
```

### 特征分布与异常值
画分布
```{r 直方图}

GetDistribution <- function(df){
  df = as.data.frame(df)
  variable.No <- ncol(df) 

  for(i in 1:variable.No){
    # 判断该列是否为数值型变量
    if (class(df[,i][1])[1] == "numeric") {
      TmpFileName <- paste("PlotHistFigures/",i,"-",colnames(df)[i],".png",sep="")
      png(file=TmpFileName)
      hist(df[,i],xlim=c(min(na.omit(df[,i])),max(na.omit(df[,i])) )) #get hist for each column
      dev.off()
    }
  }
}

GetDistribution(sample.df)
```

查看预测值分布
```{r shares分布}
hist(sample.df$shares)
boxplot(sample.df$shares)
hist(log(sample.df$shares))
```

画箱线图
```{r 箱线图}
# 绘制箱线图，并保存至文件夹内
for (col in names(sample.df)) {
  if (is.numeric(sample.df[[col]][1])){
      filename <- paste0("boxplots/",col, ".png")
      png(filename)
      boxplot(sample.df[[col]], main = col, horizontal = TRUE)
      dev.off()
  }
}
```


```{r}
library(ggplot2)
# timedelta
  ggplot(data = sample.df, aes(x = timedelta, fill=result2)) +
  geom_histogram(bins = 100, position = "fill")

# topicNo
ggplot(data = sample.df, aes(x = topicNo, fill=result2)) +
  geom_bar(position = position_dodge(width = 0.5))

ggplot(data = sample.df, aes(x = result2)) +
  geom_bar(position = position_dodge(width = 0.5))
```

## 2. 回归模型拟合

```{r log转换}
sample.df$logShares <- log(sample.df$shares)
```

```{r 划分测试集与训练集}
set.seed(20021119)
index <- sample(c(1,2), nrow(sample.df), replace = T, prob = c(0.7, 0.3))
train <- sample.df[index==1,]
test <- sample.df[index==2,]
```

```{r 模型拟合}
lm.model <- lm(shares~timedelta + n_tokens_title + n_tokens_content +
                 num_hrefs + 
    num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + 
          Comparatives.Count + Superlatives.Count + Count.Intensifiers + 
    Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height + 
    All.Possible.Meanings + noun_count + verb_count + adverb_count + 
    punc_count + title_subjectivity + 
      title_sentiment_polarity+
      isHoliday+ContentFleschReadingEase+NWordRatio+
      VWordRatio+wordRatioIn8000+global_subjectivity+global_sentiment_polarity+
      global_rate_positive_words+global_rate_negative_words+novel.of.title+ 
      dayRatio+threeDayRatio+weekRation+twoWeekRation
      -1,
    data = sample.df2)
summary(lm.model)
```
```{r}
library(car)
# 离群值检验


while (length(outlierTest(lm.model))) {
  outlierTest(lm.model)
  outlier.index <- as.numeric(rownames(
  as.data.frame(outlierTest(lm.model)[["rstudent"]])))
  sample.df2 <- sample.df2[-outlier.index,]
  lm.model <- lm(logShares~timedelta + n_tokens_title + n_tokens_content +
                   num_hrefs + 
      num_self_hrefs + num_imgs + num_videos + average_token_length + 
      data_channel_is_lifestyle + data_channel_is_entertainment + 
      data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
      data_channel_is_world + is_weekend + topicNo + 
            Comparatives.Count + Superlatives.Count + Count.Intensifiers + 
      Flesch.Kincaid.Grade.of.Title + Count.Downtoners + SyntaxTree.Height + 
      All.Possible.Meanings + noun_count + verb_count + adverb_count + 
      punc_count + title_subjectivity + 
        title_sentiment_polarity+
        isHoliday+ContentFleschReadingEase+NWordRatio+
        VWordRatio+wordRatioIn8000+global_subjectivity+global_sentiment_polarity+
        global_rate_positive_words+global_rate_negative_words+novel.of.title+ 
        dayRatio+threeDayRatio+weekRation+twoWeekRation
        -1,
      data = sample.df2)
  print(i)
  i = i + 1
}




```


```{r MAE}
train_pred <- predict(lm.model, newdata = train)
mean(abs(train_pred - train$shares))
test_pred <- predict(lm.model, newdata = test)
mean(abs(exp(test_pred) - exp(test$logShares)))
```

# 3. 分类模型拟合

## shares分箱

```{r 二分}
quantile(sample.df$shares, c(0.506))

range_capture <- function(x) {
    if (x >= 0 & x < 1408) {
        return(0)
    } else {
      return(1)
    }
}

sample.df$result <- as.factor(sapply(sample.df$shares, range_capture))

```


```{r}
selectResult2 <- function(x) {
  if (x < 1000) {
    return(1)
  } else if (x < 10000) {
    return(2)
  } else {
    return(3)
  }
}
```


```{r 三分 }
sample.df$result2 <- as.factor(sapply(sample.df$shares, selectResult2))
```

## 划分test train

```{r 划分测试集与训练集}
set.seed(20021119)
index <- sample(c(1,2), nrow(sample.df), replace = T, prob = c(0.7, 0.3))
train <- sample.df[index==1,]
test <- sample.df[index==2,]
```


处理不平衡
```{r}
library(ROSE)
train.df <- select(train, -c("Date", "HolidayName"))

table(train.df$result2)
# 过采样

# 将三分类变量转换为二分类变量
train.df$var1_new <- as.factor(model.matrix(~ as.factor(result2) - 1, 
                                            data = train.df)[, 2])
train.df$var2_new <- as.factor(model.matrix(~ as.factor(result2) - 1, 
                                            data = train.df)[, 3])
train.df$var3_new <- as.factor(model.matrix(~ as.factor(result2) - 1, 
                                            data = train.df)[, 1])
table(train.df$var1_new)
table(train.df$var2_new)
table(train.df$var3_new)

# 进行采样，分别以var1_new var2_new var3_new为过采样主变量
over_sampled1 <- ovun.sample(var1_new ~ ., data = train.df, method = "over")$data
over_sampled2 <- ovun.sample(var2_new ~ ., data = over_sampled1, p=0.35,method = "over")$data
over_sampled3 <- ovun.sample(var3_new ~ ., data = over_sampled2, p=0.33,method = "over")$data

both_sampled1 <- ovun.sample(var1_new ~ ., data = train.df, method = "both")$data
both_sampled2 <- ovun.sample(var2_new ~ ., data = over_sampled1, p=0.35,method = "both")$data
both_sampled3 <- ovun.sample(var3_new ~ ., data = over_sampled2, p=0.33,method = "both")$data

under_sampled1 <- ovun.sample(var1_new ~ ., data = train.df, method = "over")$data
under_sampled2 <- ovun.sample(var2_new ~ ., data = over_sampled1, p=0.35,method = "over")$data
under_sampled3 <- ovun.sample(var3_new ~ ., data = over_sampled2, p=0.33,method = "over")$data

rose_sampled1 <- ROSE(var1_new ~ ., data = train.df)$data
rose_sampled2 <- ROSE(var2_new ~ ., data = over_sampled1, p=0.35)$data
rose_sampled3 <- ROSE(var3_new ~ ., data = over_sampled2, p=0.33)$data
```
评估
```{r}
tree.over <-  randomForest(result2 ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=over_sampled3)

tree.under <-  randomForest(result2 ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=under_sampled3)

tree.both <-  randomForest(result2 ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=both_sampled3)

tree.rose <-  randomForest(result2 ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=rose_sampled3)
```


```{r}
plotTestROC(tree.over, "Over")
plotTestROC(tree.under, "Under")
plotTestROC(tree.both, "Both")
plotTestROC(tree.rose, "Rose")
```
 

## 随机森林

```{r 随机森林}
library(randomForest)

rf.model <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=rose_sampled3, importance=T, 
    ntree=450, mtry = 10)

rf.model
```

### 选择特征

```{r}
varImpPlot(rf.model, n.var = 30, main = "Top 30 - Variable Importance")

importance.df <- data.frame(importance(rf.model), check.names = F)
importance.df <- importance.df[order(importance.df$MeanDecreaseGini, 
                                   decreasing = T),]
head(importance.df)
```

```{r}
##交叉验证辅助评估选择特定数量的 Feature
#5 次重复十折交叉验证
set.seed(20021119)
train.cv <- replicate(5, rfcv(train.df, train$result, 
                              cv.fold = 10, step = 1.5), simplify = FALSE)
```

```{r}
#提取验证结果绘图
train.cv <- data.frame(sapply(train.cv, '[[', 'error.cv'))
train.cv$features <- rownames(train.cv)
train.cv <- reshape2::melt(train.cv, id = 'features')
train.cv$features <- as.numeric(as.character(train.cv$features))
 
train.cv.mean <- aggregate(train.cv$value, by = list(train.cv$features), FUN = mean)
head(train.cv.mean, 10)
```


```{r}
#拟合线图
library(ggplot2)
 
ggplot(train.cv.mean, aes(Group.1, x)) +
  geom_line() +
labs(title = '',x = 'Number of Features', y = 'Cross-validation error')
```

```{r}
train.cv.mean
```



```{r}
importance.df <- importance.df[order(importance.df$MeanDecreaseAccuracy, 
                                   decreasing = T),]
features <- rownames(importance.df[1:29,])

formula <- paste0("result2 ~ ", paste(features, collapse = " + "))

formula
```

```{r}
library(randomForest)

rf.model2 <- randomForest::randomForest(result2 ~ data_channel_is_world + num_imgs + data_channel_is_entertainment + num_hrefs + data_channel_is_bus + global_subjectivity + data_channel_is_tech + average_token_length + timedelta + is_weekend + num_videos + n_tokens_content + data_channel_is_socmed + global_rate_positive_words + global_sentiment_polarity + num_self_hrefs + global_rate_negative_words + title_subjectivity + VWordRatio + topicNo + Flesch.Kincaid.Grade.of.Title + novel.of.title + NWordRatio + SyntaxTree.Height + title_sentiment_polarity + threeDayRatio + data_channel_is_lifestyle + dayRatio + twoWeekRation, data=over_sampled3, importance=T, ntree=450)

rf.model2
```


Confusion Matrix
```{r}
test_pred.rf <- predict(rf.model2, newdata = test)
table(test_pred.rf, test$result)
```

### ROC & AUC

$$ 
TPR = TP / P 
$$

$$
FPR = FP(FalsePositive) / N
$$
目的是取得软分类转硬分类的概率阈值，借以评估分类效果
```{r}
library(pROC)

tableTestBinary <- function(model) {
  p <- predict(model, newdata=test)
  table(p, test$result2,dnn=c("预测值","真实值"))
}

tableTrainBinary <- function(model) {
  p <- predict(model, newdata=train)
  table(p, train$result2,dnn=c("预测值","真实值"))
}
```

```{r}
str(test$result2)

```

```{r}
plotTestROC <- function(model, theme) {
  pre_ran <- predict(model, newdata=test)
  ran_roc <- roc(test$result2, as.numeric(pre_ran), levels=c("1","3"))
  plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}


plotTrainROC <- function(model, theme) {
  pre_ran <- predict(model, newdata=train)
  ran_roc <- roc(train$result2, as.numeric(pre_ran), levels=c("1","3"))
  plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1,0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main=theme)
}
```


### 不用欠采样会发生什么事情...
```{r}
rf.model_full <- randomForest::randomForest(result2 ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data=train, importance=T, 
    ntree=450, mtry = 10)
```

```{r}
plotTestROC(rf.model_full, "随机森林+不做采样- Test")
plotTrainROC(rf.model_full, "随机森林+不做采样- Train")
tableTestBinary(rf.model_full)
tableTrainBinary(rf.model_full)

plotTestROC(rf.model, "随机森林+欠采样- Test")
plotTrainROC(rf.model, "随机森林+欠采样- Train")
tableTestBinary(rf.model)
tableTrainBinary(rf.model)

plotTestROC(rf.model2, "随机森林2+欠采样- Test")
plotTrainROC(rf.model2, "随机森林2+欠采样- Train")
tableTestBinary(rf.model2)
tableTrainBinary(rf.model2)
```



## C50


```{r}
library(C50)
c50.model <- C5.0(result ~ timedelta + n_tokens_title + 
                             n_tokens_content + 
    num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + 
    data_channel_is_lifestyle + data_channel_is_entertainment + 
    data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
    data_channel_is_world + is_weekend + topicNo + Comparatives.Count + 
    Superlatives.Count + Count.Intensifiers + Flesch.Kincaid.Grade.of.Title + 
    Count.Downtoners + SyntaxTree.Height + All.Possible.Meanings + 
    noun_count + verb_count + adverb_count + punc_count + title_subjectivity + 
    title_sentiment_polarity + isHoliday + ContentFleschReadingEase + 
    NWordRatio + VWordRatio + wordRatioIn8000 + global_subjectivity + 
    global_sentiment_polarity + global_rate_positive_words + 
    global_rate_negative_words + novel.of.title+ dayRatio + threeDayRatio +
      weekRation + twoWeekRation, data = train)

plotROC(c50.model, "C50")
tableTestBinary(c50.model)
tableTrainBinary(c50.model)
```


